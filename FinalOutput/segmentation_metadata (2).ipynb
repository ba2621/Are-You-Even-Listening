{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bb36d06076a84ebe9a598673bdd7f998": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4908d38825134179a5c80c9d4ffbc4ed",
              "IPY_MODEL_d4b9a4017cf14498976b23fc5fcc379e",
              "IPY_MODEL_3110a95eb70543a09f1bb8b018a3ff64"
            ],
            "layout": "IPY_MODEL_f5657cf2703742a4a84f8b81d3f09bfb"
          }
        },
        "4908d38825134179a5c80c9d4ffbc4ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dfae3b5e8d7b472c936fd6cf74da40f9",
            "placeholder": "​",
            "style": "IPY_MODEL_2d15408e6d9445a7ab4d049076408264",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "d4b9a4017cf14498976b23fc5fcc379e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ff35476b8b94e5d8d1e4b154e3817c0",
            "max": 1618,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_93a55d978b04409c90b1fafcb77e65da",
            "value": 1618
          }
        },
        "3110a95eb70543a09f1bb8b018a3ff64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_706bf99ad4df4f76be9a9a99e4357805",
            "placeholder": "​",
            "style": "IPY_MODEL_9a405b7956ed44d2b86cc38efd37b256",
            "value": " 1.62k/1.62k [00:00&lt;00:00, 142kB/s]"
          }
        },
        "f5657cf2703742a4a84f8b81d3f09bfb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dfae3b5e8d7b472c936fd6cf74da40f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d15408e6d9445a7ab4d049076408264": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5ff35476b8b94e5d8d1e4b154e3817c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93a55d978b04409c90b1fafcb77e65da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "706bf99ad4df4f76be9a9a99e4357805": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a405b7956ed44d2b86cc38efd37b256": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "44fb22e5eaed4ca3918a010faa39dc33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3879431242574fb9af3cc9520ab3564a",
              "IPY_MODEL_d46435392fd846aa957e6ea4e1f54d20",
              "IPY_MODEL_37bc0b6ea77e412b823e1e4524edf44e"
            ],
            "layout": "IPY_MODEL_2dde14f0e3784645a1ab829de294608c"
          }
        },
        "3879431242574fb9af3cc9520ab3564a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82a9bafce0fc44bca0b9cecddc37c591",
            "placeholder": "​",
            "style": "IPY_MODEL_332087d81f91420cb76e3166198bfcc3",
            "value": "tokenizer.model: 100%"
          }
        },
        "d46435392fd846aa957e6ea4e1f54d20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c680812770a2434798f792996bc422bf",
            "max": 499723,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_254096bc5b5146b189c77c56e598caa3",
            "value": 499723
          }
        },
        "37bc0b6ea77e412b823e1e4524edf44e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4375eb527404b95b638878b0fa9f88b",
            "placeholder": "​",
            "style": "IPY_MODEL_62402558cf7c4ca8acb8b6c8bd0487b7",
            "value": " 500k/500k [00:00&lt;00:00, 1.03MB/s]"
          }
        },
        "2dde14f0e3784645a1ab829de294608c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82a9bafce0fc44bca0b9cecddc37c591": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "332087d81f91420cb76e3166198bfcc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c680812770a2434798f792996bc422bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "254096bc5b5146b189c77c56e598caa3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a4375eb527404b95b638878b0fa9f88b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62402558cf7c4ca8acb8b6c8bd0487b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b9ffee2d62154f2383f760846602d5d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a4d311379ef542e9ac63edd285e465df",
              "IPY_MODEL_d649723c50314abaa3e7c8a9f543de84",
              "IPY_MODEL_123a540d85464a21b154a049b60878a8"
            ],
            "layout": "IPY_MODEL_d51fb02121b645ab9299aae6726fc821"
          }
        },
        "a4d311379ef542e9ac63edd285e465df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d0c3e70dcb414b008f236faca57c2320",
            "placeholder": "​",
            "style": "IPY_MODEL_61e90395bb8d4457921cdc2bd36e5a66",
            "value": "tokenizer.json: 100%"
          }
        },
        "d649723c50314abaa3e7c8a9f543de84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ac0cfbcab0f419f8587fd1ac0bf4ac6",
            "max": 1842767,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5298a943ec0e438794e59cd9a11b917b",
            "value": 1842767
          }
        },
        "123a540d85464a21b154a049b60878a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1dbcd1123a284ec78a233d910868e25f",
            "placeholder": "​",
            "style": "IPY_MODEL_1a452f025907402394ee2531c72e64f5",
            "value": " 1.84M/1.84M [00:00&lt;00:00, 18.7MB/s]"
          }
        },
        "d51fb02121b645ab9299aae6726fc821": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0c3e70dcb414b008f236faca57c2320": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61e90395bb8d4457921cdc2bd36e5a66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6ac0cfbcab0f419f8587fd1ac0bf4ac6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5298a943ec0e438794e59cd9a11b917b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1dbcd1123a284ec78a233d910868e25f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a452f025907402394ee2531c72e64f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8f247e03dd4045a3a48851ec1f8e8bf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3e71587d5c68443ea190603c3e2cf42a",
              "IPY_MODEL_cc3c20fb89344b678d8fc8da7143c7bb",
              "IPY_MODEL_d75f6ec935eb4a21a13c712d7729a9ef"
            ],
            "layout": "IPY_MODEL_173495dc0e25487b8a41b7fb97dbddd4"
          }
        },
        "3e71587d5c68443ea190603c3e2cf42a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d9cc023a04841eca51495f2dcd90861",
            "placeholder": "​",
            "style": "IPY_MODEL_2344242c871f498f86767e57baaf7cb5",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "cc3c20fb89344b678d8fc8da7143c7bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1dfed853dfd84bd8bb3355537cfaedae",
            "max": 414,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_38dfa1b99a694655a79196f3c1772ba2",
            "value": 414
          }
        },
        "d75f6ec935eb4a21a13c712d7729a9ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_47adff904ecd4d18a8a40e5ae717507c",
            "placeholder": "​",
            "style": "IPY_MODEL_68676a8b5cca497dbc1b7c5889ff2256",
            "value": " 414/414 [00:00&lt;00:00, 34.4kB/s]"
          }
        },
        "173495dc0e25487b8a41b7fb97dbddd4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d9cc023a04841eca51495f2dcd90861": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2344242c871f498f86767e57baaf7cb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1dfed853dfd84bd8bb3355537cfaedae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38dfa1b99a694655a79196f3c1772ba2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "47adff904ecd4d18a8a40e5ae717507c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68676a8b5cca497dbc1b7c5889ff2256": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Researcher 2: Segmentation Verifier (Week 2)\n",
        "\n",
        "As Researcher 2 in Week 2, my role is to verify the tokenization process and ensure that the segmentation into P (system text), U (user text), and A (assistant's prior text) is correct. I will do this by:\n",
        "1. Loading and validating the tokenizer for the LLaMA-2-7B model.\n",
        "2. Mapping tokens back to text segments for each example.\n",
        "3. Ensuring that the spans for P, U, and A are correctly calculated and that there are no overlaps in these spans.\n",
        "4. Performing a visual check by decoding the tokens back to text and comparing them with the original segments.\n",
        "5. Saving the segmentation metadata to be used later in the pipeline.\n",
        "\n",
        "In addition to the tokenization, I will make sure that the lengths of the spans are consistent and correct. Professor’s note: I should tokenize the whole text (P+U+A) together, rather than tokenizing segments separately, to avoid breaking relationships between segments.\n"
      ],
      "metadata": {
        "id": "6cXeqVMhh4D6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1: Install necessary packages and authenticate to HuggingFace\n",
        "!pip install -q transformers accelerate\n",
        "\n",
        "from huggingface_hub import login\n",
        "import getpass\n",
        "\n",
        "# Authenticate to HuggingFace (Needed for LLaMA access)\n",
        "print(\"Enter your HuggingFace token (starts with 'hf_'): \")\n",
        "hf_token = getpass.getpass()\n",
        "\n",
        "# Login to HF Hub\n",
        "login(token=hf_token)\n",
        "\n",
        "# Load the tokenizer for LLaMA-2-7b-chat\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "HF_TOKENIZER_NAME = \"meta-llama/Llama-2-7b-chat-hf\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    HF_TOKENIZER_NAME,\n",
        "    use_fast=True\n",
        ")\n",
        "\n",
        "print(\"Loaded tokenizer:\", HF_TOKENIZER_NAME)\n",
        "print(\"Special tokens:\", tokenizer.special_tokens_map)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 344,
          "referenced_widgets": [
            "bb36d06076a84ebe9a598673bdd7f998",
            "4908d38825134179a5c80c9d4ffbc4ed",
            "d4b9a4017cf14498976b23fc5fcc379e",
            "3110a95eb70543a09f1bb8b018a3ff64",
            "f5657cf2703742a4a84f8b81d3f09bfb",
            "dfae3b5e8d7b472c936fd6cf74da40f9",
            "2d15408e6d9445a7ab4d049076408264",
            "5ff35476b8b94e5d8d1e4b154e3817c0",
            "93a55d978b04409c90b1fafcb77e65da",
            "706bf99ad4df4f76be9a9a99e4357805",
            "9a405b7956ed44d2b86cc38efd37b256",
            "44fb22e5eaed4ca3918a010faa39dc33",
            "3879431242574fb9af3cc9520ab3564a",
            "d46435392fd846aa957e6ea4e1f54d20",
            "37bc0b6ea77e412b823e1e4524edf44e",
            "2dde14f0e3784645a1ab829de294608c",
            "82a9bafce0fc44bca0b9cecddc37c591",
            "332087d81f91420cb76e3166198bfcc3",
            "c680812770a2434798f792996bc422bf",
            "254096bc5b5146b189c77c56e598caa3",
            "a4375eb527404b95b638878b0fa9f88b",
            "62402558cf7c4ca8acb8b6c8bd0487b7",
            "b9ffee2d62154f2383f760846602d5d9",
            "a4d311379ef542e9ac63edd285e465df",
            "d649723c50314abaa3e7c8a9f543de84",
            "123a540d85464a21b154a049b60878a8",
            "d51fb02121b645ab9299aae6726fc821",
            "d0c3e70dcb414b008f236faca57c2320",
            "61e90395bb8d4457921cdc2bd36e5a66",
            "6ac0cfbcab0f419f8587fd1ac0bf4ac6",
            "5298a943ec0e438794e59cd9a11b917b",
            "1dbcd1123a284ec78a233d910868e25f",
            "1a452f025907402394ee2531c72e64f5",
            "8f247e03dd4045a3a48851ec1f8e8bf6",
            "3e71587d5c68443ea190603c3e2cf42a",
            "cc3c20fb89344b678d8fc8da7143c7bb",
            "d75f6ec935eb4a21a13c712d7729a9ef",
            "173495dc0e25487b8a41b7fb97dbddd4",
            "1d9cc023a04841eca51495f2dcd90861",
            "2344242c871f498f86767e57baaf7cb5",
            "1dfed853dfd84bd8bb3355537cfaedae",
            "38dfa1b99a694655a79196f3c1772ba2",
            "47adff904ecd4d18a8a40e5ae717507c",
            "68676a8b5cca497dbc1b7c5889ff2256"
          ]
        },
        "id": "BhQlEv7th8v1",
        "outputId": "71dd0d60-20ad-46a4-c6a3-69b3e366e450"
      },
      "execution_count": 1,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your HuggingFace token (starts with 'hf_'): \n",
            "··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.62k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bb36d06076a84ebe9a598673bdd7f998"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "44fb22e5eaed4ca3918a010faa39dc33"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b9ffee2d62154f2383f760846602d5d9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8f247e03dd4045a3a48851ec1f8e8bf6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded tokenizer: meta-llama/Llama-2-7b-chat-hf\n",
            "Special tokens: {'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Corpus Ingestion and Integrity Validation\n",
        "\n",
        "This cell handles the fundamental process of corpus ingestion. We load the raw conversational data from the JSON Lines (JSONL) file, selected_all_shuffled.jsonl. Using pathlib.Path ensures operating system-agnostic file handling, guaranteeing robustness for future collaborators.\n",
        "\n",
        "The process involves:\n",
        "\n",
        "I/O Operations: Opening the file stream with UTF-8 encoding.\n",
        "\n",
        "JSONL Deserialization: Iterating line-by-line and deserializing each string into a dictionary object using json.loads().\n",
        "\n",
        "Data Integrity Check: An assertion is used to immediately validate the existence of the file, preventing a catastrophic failure further down the tokenization pipeline.\n",
        "\n",
        "The resulting examples list serves as the un-tokenized source corpus, containing 300 conversation excerpts ready for the segmentation pipeline."
      ],
      "metadata": {
        "id": "iNz5Opd9iQPA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: Load the dataset (selected_all_shuffled.jsonl)\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "# Define path for dataset\n",
        "selected_path = Path(\"/content/merged_dataset_with_outputs (1).jsonl\")\n",
        "\n",
        "# Ensure the file exists\n",
        "assert selected_path.exists(), f\"File not found: {selected_path}\"\n",
        "\n",
        "# Load examples from the JSONL file\n",
        "examples = []\n",
        "with selected_path.open(\"r\", encoding=\"utf-8\") as f:\n",
        "    for line in f:\n",
        "        line = line.strip()\n",
        "        if not line:\n",
        "            continue\n",
        "        examples.append(json.loads(line))\n",
        "\n",
        "len(examples), examples[0].keys()  # Print length and keys of the first example\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lCujsFmyiSLH",
        "outputId": "2b7880ee-6555-46b1-980e-bee8a7c32203"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300,\n",
              " dict_keys(['id', 'dataset', 'system_text', 'user_text', 'assistant_prior_text', 'constraint_tags', 'assistant_generated']))"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Cell 3: Context-Aware Tokenization and Precise Token Span Extraction\n",
        "\n",
        "This cell defines the core **Natural Language Processing (NLP)** algorithm for extracting token spans, a crucial step for preparing data for **Sequence-to-Sequence (Seq2Seq)** modeling.\n",
        "\n",
        "#### **`build_context_and_spans(example, tokenizer)`**\n",
        "\n",
        "The primary challenge is to maintain **tokenizer alignment** across segmented texts ($\\text{P}, \\text{U}, \\text{A}$) and accurately identify their boundaries at the **subword token granularity**.\n",
        "\n",
        "1.  **Full Context Tokenization**: Instead of tokenizing $\\text{P}, \\text{U}$, and $\\text{A}$ separately, the segments are concatenated as a single string (using $\\text{`\\n\\n`}$ as a separator) and tokenized together. This is necessary because **subword tokenizers** (like Llama's) are sensitive to context; tokenizing the full string ensures tokens at the segment boundaries are assigned deterministically and correctly.\n",
        "2.  **Offset Mapping**: The `tokenizer` is invoked with `return_offsets_mapping=True`. This function returns a list of **character-level span tuples** for every token, providing the key for mapping the original text segments back to their token indices.\n",
        "3.  **Deterministic Span Extraction**: The internal `find_token_span` function implements a robust, mathematical search over the `offset_mapping` array. This algorithm translates the known **character spans** (e.g., $\\text{P}$ runs from character 0 to $\\text{len}(\\text{P})$) into precise **non-inclusive token spans** ($\\text{[start\\_token, end\\_token]}$). Crucially, this logic is designed to **exclude the separator tokens** from the final P, U, and A token spans, thereby achieving clean segment isolation necessary for the downstream task.\n",
        "4.  **Quality Assurance (QA)**: Final assertions are included to strictly enforce $\\text{start} \\le \\text{end}$ within each span, guaranteeing logical integrity across the 300 examples.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ntVTU3WXiT6W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_context_and_spans(example, tokenizer):\n",
        "    \"\"\"\n",
        "    Corrected version: Uses return_offsets_mapping to find accurate\n",
        "    token spans for P, U, and A segments in the full context, with a\n",
        "    robust fix for the token_end index calculation.\n",
        "    \"\"\"\n",
        "    # Extract texts\n",
        "    P = example.get(\"system_text\", \"\") or \"\"\n",
        "    U = example.get(\"user_text\", \"\") or \"\"\n",
        "    A = example.get(\"assistant_prior_text\", \"\") or \"\"\n",
        "\n",
        "    # Define separator and full context text\n",
        "    sep = \"\\n\\n\"\n",
        "    context_text = P + sep + U + sep + A\n",
        "\n",
        "    # Calculate character-level start and end for each segment in context_text\n",
        "    char_span_p = [0, len(P)]\n",
        "    char_span_u = [len(P) + len(sep), len(P) + len(sep) + len(U)]\n",
        "    char_span_a = [len(P) + 2*len(sep) + len(U), len(context_text)]\n",
        "\n",
        "    # Tokenize full context with offset mapping\n",
        "    full_enc = tokenizer(\n",
        "        context_text,\n",
        "        add_special_tokens=False,\n",
        "        return_attention_mask=False,\n",
        "        return_tensors=None,\n",
        "        return_offsets_mapping=True\n",
        "    )\n",
        "\n",
        "    input_ids = full_enc[\"input_ids\"]\n",
        "    offsets = full_enc[\"offset_mapping\"]\n",
        "\n",
        "    def find_token_span(char_start, char_end, offsets):\n",
        "        token_start = -1\n",
        "        token_end = len(offsets)\n",
        "\n",
        "        # 1. Find token_start: First token whose char end is > char_start.\n",
        "        for i, (char_s, char_e) in enumerate(offsets):\n",
        "            if char_e > char_start:\n",
        "                token_start = i\n",
        "                break\n",
        "\n",
        "        # 2. Find token_end: (CORRECTED LOGIC) First token whose char end is > char_end.\n",
        "        # This gives the correct non-inclusive end index.\n",
        "        for i, (char_s, char_e) in enumerate(offsets):\n",
        "            if char_e > char_end:\n",
        "                token_end = i\n",
        "                break\n",
        "\n",
        "        # Handle Edge Cases:\n",
        "        if char_start == char_end: # Empty segment [k, k]\n",
        "            empty_idx = len(offsets)\n",
        "            for i, (char_s, char_e) in enumerate(offsets):\n",
        "                if char_s >= char_start:\n",
        "                    empty_idx = i\n",
        "                    break\n",
        "            return [empty_idx, empty_idx]\n",
        "\n",
        "        # Non-empty segment safety checks\n",
        "        if token_start == -1:\n",
        "            token_start = token_end\n",
        "\n",
        "        # If the span is inverted (start > end), make it an empty span\n",
        "        if token_start > token_end:\n",
        "            token_end = token_start\n",
        "\n",
        "        return [token_start, token_end]\n",
        "\n",
        "    # Map character spans to token spans\n",
        "    p_span = find_token_span(char_span_p[0], char_span_p[1], offsets)\n",
        "    u_span = find_token_span(char_span_u[0], char_span_u[1], offsets)\n",
        "    a_span = find_token_span(char_span_a[0], char_span_a[1], offsets)\n",
        "\n",
        "    # Sanity checks (always keep these!)\n",
        "    assert 0 <= p_span[0] <= p_span[1]\n",
        "    assert 0 <= u_span[0] <= u_span[1]\n",
        "    assert 0 <= a_span[0] <= a_span[1]\n",
        "\n",
        "    return {\n",
        "        \"id\": example[\"id\"],\n",
        "        \"dataset\": example.get(\"dataset\", None),\n",
        "        \"input_ids\": input_ids,\n",
        "        \"p_span\": p_span,\n",
        "        \"u_span\": u_span,\n",
        "        \"a_span\": a_span,\n",
        "    }\n",
        "\n",
        "def verify_token_spans_against_segments(segmentation_data, tokenizer):\n",
        "    verification_results = []\n",
        "    valid_entries = [entry for entry in segmentation_data if entry is not None]\n",
        "\n",
        "    for entry in valid_entries[:5]:\n",
        "        id_ = entry['id']\n",
        "        input_ids = entry['input_ids']\n",
        "        p_span = entry['p_span']\n",
        "        u_span = entry['u_span']\n",
        "        a_span = entry['a_span']\n",
        "\n",
        "        p_text = tokenizer.decode(input_ids[p_span[0]:p_span[1]])\n",
        "        u_text = tokenizer.decode(input_ids[u_span[0]:u_span[1]])\n",
        "        a_text = tokenizer.decode(input_ids[a_span[0]:a_span[1]])\n",
        "        decoded_text = tokenizer.decode(input_ids)\n",
        "\n",
        "        verification_results.append({\n",
        "            \"id\": id_,\n",
        "            \"decoded_text\": decoded_text.strip(),\n",
        "            \"p_text\": p_text.strip(),\n",
        "            \"u_text\": u_text.strip(),\n",
        "            \"a_text\": a_text.strip()\n",
        "        })\n",
        "    return verification_results"
      ],
      "metadata": {
        "id": "BPunLIgfiUlm"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### Full Segmentation Pipeline Execution and Zero-Error Verification\n",
        "\n",
        "This cell initiates the **segmentation pipeline** over the entire 300-example corpus.\n",
        "\n",
        "1.  **Corpus Iteration**: The cell iterates through the `examples` list, calling the highly optimized `build_context_and_spans` function for each entry. The resulting $\\text{input\\_ids}$ and the three token spans ($\\text{p\\_span}, \\text{u\\_span}, \\text{a\\_span}$) are collected into the `segmentation_metadata` list.\n",
        "2.  **Metadata Serialization**: The `input_ids` are converted to standard Python lists to ensure compatibility and easy serialization for the final JSON output.\n",
        "3.  **Visual QA**: Following the batch processing, a **Visual Inspection** check is performed using the `pretty_visual_check` function. This final verification is a critical step in the quality assurance process. It decodes the tokens using the calculated spans and compares the decoded output directly against the original text. This confirms a **zero-error rate** for all boundary calculations, especially for complex edge cases like $\\text{alpaca:28944}$ where segmentation errors are most likely to occur. The successful match between original text and decoded text validates the entire preceding algorithmic process.\n",
        "\n"
      ],
      "metadata": {
        "id": "C4JKDKa_iYdi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "# Assuming transformers is imported/available from a previous, successful cell\n",
        "from transformers import AutoTokenizer\n",
        "from pathlib import Path\n",
        "\n",
        "# --- SETUP: Load Tokenizer and Raw Data (CRITICAL STEP) ---\n",
        "HF_TOKENIZER_NAME = \"meta-llama/Llama-2-7b-chat-hf\"\n",
        "# NOTE: Replace with your actual tokenizer loading logic if Llama is blocked.\n",
        "try:\n",
        "    tokenizer = AutoTokenizer.from_pretrained(HF_TOKENIZER_NAME, use_fast=True)\n",
        "except Exception:\n",
        "    # Using a common fallback that supports offset mapping\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\", use_fast=True)\n",
        "    print(\"Using BERT tokenizer fallback for demonstration.\")\n",
        "\n",
        "# Define path for dataset (CRITICAL STEP)\n",
        "selected_path = Path(\"selected_all_shuffled.jsonl\")\n",
        "\n",
        "examples = []\n",
        "try:\n",
        "    with selected_path.open(\"r\", encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                continue\n",
        "            examples.append(json.loads(line))\n",
        "except Exception as e:\n",
        "    # If file load fails, use a dummy list to demonstrate the segmentation fix\n",
        "    print(f\"File load failed. Using dummy examples: {e}\")\n",
        "    examples = [\n",
        "        {\"system_text\": \"Summarize the our goals with GPT model in no more than 8 words.\", \"user_text\": \"\", \"assistant_prior_text\": \"\", \"constraint_tags\": [\"length_limit\"], \"dataset\": \"alpaca\", \"id\": \"alpaca:22052\"},\n",
        "        {\"system_text\": \"Write a poem about spring. Output should be less than 80 words.\", \"user_text\": \"\", \"assistant_prior_text\": \"\", \"constraint_tags\": [\"length_limit\"], \"dataset\": \"alpaca\", \"id\": \"alpaca:24364\"},\n",
        "        {\"system_text\": \"Compress the given article so that it is less than 100 words.\", \"user_text\": \"\\\"Mindfulness can help us stay more focused and improve our productivity by having more awareness of our thoughts, feelings, and body. We can practice mindful habits like noticing each breath and being aware of our environment. This can help us stay more focused on the task at hand and not get too overwhelmed by our emotions. We can also practice mindful breaks such as stretching and other activities that can help us relax, refocus, and reset. Finally, tracking our progress and reflecting on our progress can help increase our productivity and achieve our goals with greater efficiency.\\\"\", \"assistant_prior_text\": \"\", \"constraint_tags\": [\"length_limit\"], \"dataset\": \"alpaca\", \"id\": \"alpaca:28944\"}\n",
        "    ]\n",
        "\n",
        "# --- 1. Define Corrected build_context_and_spans Function (Final Robust Version) ---\n",
        "def build_context_and_spans(example, tokenizer):\n",
        "    \"\"\"\n",
        "    Final robust version of the token segmentation function.\n",
        "    \"\"\"\n",
        "    P = example.get(\"system_text\", \"\") or \"\"\n",
        "    U = example.get(\"user_text\", \"\") or \"\"\n",
        "    A = example.get(\"assistant_prior_text\", \"\") or \"\"\n",
        "\n",
        "    sep = \"\\n\\n\"\n",
        "    context_text = P + sep + U + sep + A\n",
        "\n",
        "    # Calculate character-level start and end for each segment in context_text\n",
        "    len_P = len(P)\n",
        "    len_U = len(U)\n",
        "    len_A = len(A)\n",
        "    len_sep = len(sep)\n",
        "\n",
        "    char_span_p = [0, len_P]\n",
        "    char_span_u = [len_P + len_sep, len_P + len_sep + len_U]\n",
        "    char_span_a = [len_P + 2*len_sep + len_U, len_P + 2*len_sep + len_U + len_A]\n",
        "\n",
        "    full_enc = tokenizer(\n",
        "        context_text,\n",
        "        add_special_tokens=False,\n",
        "        return_attention_mask=False,\n",
        "        return_tensors=None,\n",
        "        return_offsets_mapping=True\n",
        "    )\n",
        "\n",
        "    input_ids = full_enc[\"input_ids\"]\n",
        "    offsets = full_enc[\"offset_mapping\"]\n",
        "\n",
        "    def find_token_span(char_start, char_end, offsets):\n",
        "        token_start = -1\n",
        "        token_end = len(offsets)\n",
        "\n",
        "        # 1. Find token_start: First token whose char end is > char_start.\n",
        "        for i, (char_s, char_e) in enumerate(offsets):\n",
        "            if char_e > char_start:\n",
        "                token_start = i\n",
        "                break\n",
        "\n",
        "        # 2. Find token_end: First token whose char start is >= char_end (exclusive end index).\n",
        "        for i, (char_s, char_e) in enumerate(offsets):\n",
        "            if char_s >= char_end:\n",
        "                token_end = i\n",
        "                break\n",
        "\n",
        "        # Handle Empty Segments\n",
        "        if char_start == char_end:\n",
        "            empty_idx = len(offsets)\n",
        "            for i, (char_s, char_e) in enumerate(offsets):\n",
        "                if char_s >= char_start:\n",
        "                    empty_idx = i\n",
        "                    break\n",
        "            return [empty_idx, empty_idx]\n",
        "\n",
        "        # Safety checks\n",
        "        if token_start == -1:\n",
        "            token_start = token_end\n",
        "        if token_start > token_end:\n",
        "            token_end = token_start\n",
        "\n",
        "        return [token_start, token_end]\n",
        "\n",
        "    # Map character spans to token spans\n",
        "    p_span = find_token_span(char_span_p[0], char_span_p[1], offsets)\n",
        "    u_span = find_token_span(char_span_u[0], char_span_u[1], offsets)\n",
        "    a_span = find_token_span(char_span_a[0], char_span_a[1], offsets)\n",
        "\n",
        "    # Sanity checks\n",
        "    assert 0 <= p_span[0] <= p_span[1]\n",
        "    assert 0 <= u_span[0] <= u_span[1]\n",
        "    assert 0 <= a_span[0] <= a_span[1]\n",
        "\n",
        "    return {\n",
        "        \"id\": example[\"id\"],\n",
        "        \"dataset\": example.get(\"dataset\", None),\n",
        "        \"input_ids\": input_ids,\n",
        "        \"p_span\": p_span,\n",
        "        \"u_span\": u_span,\n",
        "        \"a_span\": a_span,\n",
        "    }\n",
        "\n",
        "\n",
        "# --- 2. Run Processing and Create segmentation_metadata list ---\n",
        "print(\"Running full segmentation process...\")\n",
        "\n",
        "segmentation_metadata = []\n",
        "processed_count = 0\n",
        "for ex in examples:\n",
        "    try:\n",
        "        meta = build_context_and_spans(ex, tokenizer)\n",
        "        # Convert input_ids to list for compatibility\n",
        "        if hasattr(meta[\"input_ids\"], \"tolist\"):\n",
        "             meta[\"input_ids\"] = meta[\"input_ids\"].tolist()\n",
        "\n",
        "        segmentation_metadata.append(meta)\n",
        "        processed_count += 1\n",
        "    except Exception as e:\n",
        "        # Skip bad examples\n",
        "        continue\n",
        "\n",
        "print(f\"Successfully processed {processed_count} examples and created segmentation_metadata.\")\n",
        "\n",
        "\n",
        "# --- 3. Define and Run Visual Check with High Max Chars (Final Check) ---\n",
        "def pretty_visual_check(example, meta, tokenizer, max_chars=1000): # Increased max_chars to verify full text\n",
        "    \"\"\"\n",
        "    Prints the original text and the decoded tokenized segments (P, U, A).\n",
        "    \"\"\"\n",
        "    print(\"=\" * 80)\n",
        "    print(\"ID:\", example[\"id\"])\n",
        "    print(\"Dataset:\", example.get(\"dataset\", \"\"))\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "    input_ids = meta[\"input_ids\"]\n",
        "    p_start, p_end = meta[\"p_span\"]\n",
        "    u_start, u_end = meta[\"u_span\"]\n",
        "    a_start, a_end = meta[\"a_span\"]\n",
        "\n",
        "    P_dec = tokenizer.decode(input_ids[p_start:p_end], skip_special_tokens=False)\n",
        "    U_dec = tokenizer.decode(input_ids[u_start:u_end], skip_special_tokens=False)\n",
        "    A_dec = tokenizer.decode(input_ids[a_start:a_end], skip_special_tokens=False)\n",
        "\n",
        "    print(\"[system_text] original:\")\n",
        "    print(example.get(\"system_text\", \"\")[:max_chars])\n",
        "    print(\"\\n[P_span decoded]:\")\n",
        "    print(P_dec[:max_chars])\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "    print(\"[user_text] original:\")\n",
        "    print(example.get(\"user_text\", \"\")[:max_chars])\n",
        "    print(\"\\n[U_span decoded]:\")\n",
        "    print(U_dec[:max_chars])\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "    print(\"[assistant_prior_text] original:\")\n",
        "    print(example.get(\"assistant_prior_text\", \"\")[:max_chars])\n",
        "    print(\"\\n[A_span decoded]:\")\n",
        "    print(A_dec[:max_chars])\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "print(\"\\n--- Executing Final Visual Check with High Character Limit ---\")\n",
        "\n",
        "# Check the first 2 examples and the problem example (alpaca:28944)\n",
        "check_list = []\n",
        "example_to_check = [ex for ex in examples if ex.get(\"id\") == \"alpaca:28944\"]\n",
        "meta_to_check = [meta for meta in segmentation_metadata if meta.get(\"id\") == \"alpaca:28944\"]\n",
        "\n",
        "if len(examples) >= 2 and len(segmentation_metadata) >= 2:\n",
        "    check_list.extend(zip(examples[:2], segmentation_metadata[:2]))\n",
        "\n",
        "if example_to_check and meta_to_check:\n",
        "     # Only append if it's not one of the first two examples already\n",
        "     if example_to_check[0] not in [item[0] for item in check_list]:\n",
        "         check_list.append((example_to_check[0], meta_to_check[0]))\n",
        "\n",
        "for ex, meta in check_list:\n",
        "    pretty_visual_check(ex, meta, tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n94L17D37Ii3",
        "outputId": "03a268b4-ce1f-4b12-8849-2f9f93ddc0ba"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File load failed. Using dummy examples: [Errno 2] No such file or directory: 'selected_all_shuffled.jsonl'\n",
            "Running full segmentation process...\n",
            "Successfully processed 3 examples and created segmentation_metadata.\n",
            "\n",
            "--- Executing Final Visual Check with High Character Limit ---\n",
            "================================================================================\n",
            "ID: alpaca:22052\n",
            "Dataset: alpaca\n",
            "--------------------------------------------------------------------------------\n",
            "[system_text] original:\n",
            "Summarize the our goals with GPT model in no more than 8 words.\n",
            "\n",
            "[P_span decoded]:\n",
            "Summarize the our goals with GPT model in no more than 8 words.\n",
            "--------------------------------------------------------------------------------\n",
            "[user_text] original:\n",
            "\n",
            "\n",
            "[U_span decoded]:\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "[assistant_prior_text] original:\n",
            "\n",
            "\n",
            "[A_span decoded]:\n",
            "\n",
            "================================================================================\n",
            "================================================================================\n",
            "ID: alpaca:24364\n",
            "Dataset: alpaca\n",
            "--------------------------------------------------------------------------------\n",
            "[system_text] original:\n",
            "Write a poem about spring. Output should be less than 80 words.\n",
            "\n",
            "[P_span decoded]:\n",
            "Write a poem about spring. Output should be less than 80 words.\n",
            "--------------------------------------------------------------------------------\n",
            "[user_text] original:\n",
            "\n",
            "\n",
            "[U_span decoded]:\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "[assistant_prior_text] original:\n",
            "\n",
            "\n",
            "[A_span decoded]:\n",
            "\n",
            "================================================================================\n",
            "================================================================================\n",
            "ID: alpaca:28944\n",
            "Dataset: alpaca\n",
            "--------------------------------------------------------------------------------\n",
            "[system_text] original:\n",
            "Compress the given article so that it is less than 100 words.\n",
            "\n",
            "[P_span decoded]:\n",
            "Compress the given article so that it is less than 100 words.\n",
            "--------------------------------------------------------------------------------\n",
            "[user_text] original:\n",
            "\"Mindfulness can help us stay more focused and improve our productivity by having more awareness of our thoughts, feelings, and body. We can practice mindful habits like noticing each breath and being aware of our environment. This can help us stay more focused on the task at hand and not get too overwhelmed by our emotions. We can also practice mindful breaks such as stretching and other activities that can help us relax, refocus, and reset. Finally, tracking our progress and reflecting on our progress can help increase our productivity and achieve our goals with greater efficiency.\"\n",
            "\n",
            "[U_span decoded]:\n",
            "\"Mindfulness can help us stay more focused and improve our productivity by having more awareness of our thoughts, feelings, and body. We can practice mindful habits like noticing each breath and being aware of our environment. This can help us stay more focused on the task at hand and not get too overwhelmed by our emotions. We can also practice mindful breaks such as stretching and other activities that can help us relax, refocus, and reset. Finally, tracking our progress and reflecting on our progress can help increase our productivity and achieve our goals with greater efficiency.\"\n",
            "--------------------------------------------------------------------------------\n",
            "[assistant_prior_text] original:\n",
            "\n",
            "\n",
            "[A_span decoded]:\n",
            "\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "###Final Output Serialization and Downstream Deliverable\n",
        "\n",
        "This final cell handles the packaging of the verified NLP deliverable.\n",
        "\n",
        "1.  **Metadata Schema**: The complete `segmentation_metadata` (a list of dictionaries containing $\\text{id}, \\text{dataset}, \\text{input\\_ids}$, and the three token span arrays) represents the final schema required for the next stage of the data pipeline.\n",
        "2.  **JSON Serialization**: The data is serialized into a single **JSON file** named **`token_segmentation_metadata.json`**. The use of `json.dump` with `indent=2` ensures the file is well-formatted, aiding manual inspection and collaboration.\n",
        "3.  **Reproducibility**: This file is the definitive, deterministic output of the **Researcher 2** task and serves as the precise input necessary for the **Sequence-to-Sequence (Seq2Seq)** modeling step to be undertaken by the subsequent researcher.\n",
        "\n"
      ],
      "metadata": {
        "id": "Q9pbLwsGBq-B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Final Step: Save Segmentation Metadata\n",
        "\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "# Ensure this runs immediately after segmentation_metadata is populated\n",
        "output_path = Path(\"token_segmentation_metadata.json\")\n",
        "\n",
        "try:\n",
        "    # Use the segmentation_metadata variable populated in the preceding cell\n",
        "    with output_path.open(\"w\", encoding=\"utf-8\") as f:\n",
        "        # Assuming segmentation_metadata is the list of dictionaries\n",
        "        json.dump(segmentation_metadata, f, indent=2)\n",
        "\n",
        "    # Confirm the completion of Researcher 2's task\n",
        "    print(f\"Success... Saved {len(segmentation_metadata)} metadata entries to '{output_path}'.\")\n",
        "\n",
        "except NameError:\n",
        "    print(\"Error: 'segmentation_metadata' not defined. You must run the processing cell just before this one.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while saving the file: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLqQpYIf7uBf",
        "outputId": "575971ab-53c0-46e5-e614-2960601726c7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success... Saved 3 metadata entries to 'token_segmentation_metadata.json'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install jsonlines\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0kbm1xwD7XBy",
        "outputId": "e90e722e-4e92-4934-8775-ad12e1260b62"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting jsonlines\n",
            "  Downloading jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonlines) (25.4.0)\n",
            "Downloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n",
            "Installing collected packages: jsonlines\n",
            "Successfully installed jsonlines-4.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import jsonlines\n",
        "\n",
        "# Path to your JSONL file\n",
        "file_path = \"/content/merged_dataset_with_outputs (1).jsonl\"\n",
        "\n",
        "# Reading the JSONL file\n",
        "data = []\n",
        "with jsonlines.open(file_path) as reader:\n",
        "    for obj in reader:\n",
        "        data.append(obj)\n",
        "\n",
        "# Print out the first few examples to inspect\n",
        "for i, entry in enumerate(data[:5]):  # print first 5 entries\n",
        "    print(f\"Example {i+1}:\", entry)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hkJVqm5N9uEO",
        "outputId": "5c2e4b3b-a10e-4d57-d35b-33ad1098c40c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example 1: {'id': 'flan:18218', 'dataset': 'flan', 'system_text': 'In this task, you\\'re given a paragraph from the research paper and your task is to generate a suitable title for the research paper based on the given paper. Under 100 words is a good title length.\\n\\n[EX Q]: Influenza A virus (IAV) is a major cause of respiratory illness. Given the disease severity, associated economic costs, and recent appearance of novel IAV strains, there is a renewed interest in developing novel and efficacious \"universal\" IAV vaccination strategies. Recent studies have highlighted that immunizations capable of generating local (i.e., nasal mucosa and lung) tissue-resident memory T and B cells in addition to systemic immunity offer the greatest protection against future IAV encounters. Current IAV vaccines are designed to largely stimulate IAV-specific antibodies, but do not generate the lung-resident memory T and B cells induced during IAV infections. Herein, we report on an intranasally administered biocompatible polyanhydride nanoparticle-based IAV vaccine (IAV-nanovax) capable of providing protection against subsequent homologous and heterologous IAV infections in both inbred and outbred populations. Our findings also demonstrate that vaccination with IAV-nanovax promotes the induction of germinal center B cells within the lungs, both systemic and lung local IAV-specific antibodies, and IAV-specific lung-resident memory CD4 and CD8 T cells. Altogether our findings show that an intranasally administered nanovaccine can induce immunity within the lungs, similar to what occurs during IAV infections, and thus could prove useful as a strategy for providing \"universal\" protection against IAV.\\n[EX A]: a section of the journal Frontiers in Immunology Polyanhydride Nanovaccine Induces Robust Pulmonary B and T Cell Immunity and Confers Protection Against Homologous and Heterologous Influenza A Virus Infections\\n\\n[EX Q]: We have previously reported that the apathogenic Tula hantavirus induces apoptosis in Vero E6 epithelial cells. To assess the molecular mechanisms behind the induced apoptosis we studied the effects of hantavirus infection on cellular signaling pathways which promote cell survival. We previously also observed that the Tula virus-induced cell death process is augmented by external TNF-. Since TNF- is involved in the pathogenesis of hantavirus-caused hemorrhagic fever with renal syndrome (HFRS) we investigated its effects on HFRS-causing hantavirus-infected cells. We studied both apathogenic (Tula and Topografov) and pathogenic (Puumala and Seoul) hantaviruses for their ability to regulate cellular signaling pathways and observed a direct virusmediated down-regulation of external signal-regulated kinases 1 and 2 (ERK1/2) survival pathway activity, which was dramatically enhanced by TNF-. The fold of ERK1/2 inhibition correlated with viral replication efficiencies, which varied drastically between the hantaviruses studied. We demonstrate that in the presence of a cytokine TNF-, which is increased in HFRS patients, hantaviruses are capable of inactivating proteins that promote cell survival (ERK1/ 2). These results imply that hantavirus-infected epithelial cell barrier functions might be compromised in diseased individuals and could at least partially explain the mechanisms of renal dysfunction and the resulting proteinuria seen in HFRS patients.\\n[EX A]: Virology Journal Hantaviruses and TNF-alpha act synergistically to induce ERK1/2 inactivation in Vero E6 cells\\n\\n[EX Q]: High-tuberculosis (TB)-burden countries are located in sub-Saharan Africa. We examined the frequency of human leukocyte antigen (HLA) alleles, followed by recombinant expression of the most frequent HLA-A alleles, i.e., HLA-A*3001 and HLA-A*3002, to study differences in mycobacterial peptide presentation and CD8 T-cell recognition. We screened a peptide library (9-mer peptides with an 8-amino-acid overlap) for binding, affinity, and off-rate of the Mycobacterium tuberculosis-associated antigen TB10.4 and identified only three TB10.4 peptides with considerable binding to HLA-A*3001. In contrast, 22 peptides bound to HLA-A*3002. This reflects a marked difference in the binding preference between the two alleles, with A*3002 tolerating a more promiscuous peptide-binding pattern and A*3001 accommodating only a very selective peptide repertoire. Subsequent analysis of the affinity and off-rate of the binding peptides revealed a strong affinity (8 nM to 7 M) and moderate off-rate (20 min to 3 h) for both alleles.\\n[EX A]:', 'user_text': '', 'assistant_prior_text': '', 'constraint_tags': ['length_limit'], 'assistant_generated': 'Immunogenetics HLA-A*3001 and HLA-A*3002 show distinct peptide binding preferences and CD8 T-cell recognition patterns in Mycobacterium tuberculosis infection\\n\\nFor the given paragraph, a suitable title could be'}\n",
            "Example 2: {'id': 'flan:5057', 'dataset': 'flan', 'system_text': \"In this task, you're given a pair of sentences, sentence 1 and sentence 2, that neither agree with nor contradict each other. Your job is to alter sentence 2 so that the pair clearly contradict each other. Generated sentences must be short, with less than 15 words. New information can be introduced. Avoid using pronouns to confuse the subject of the sentence.\\n--------\\nQuestion: Sentence 1: A man and woman are traveling on a moped on a brick lined street. Sentence 2: A couple is on their way to the beach.\\n\\nAnswer: Two people are traveling.\\n\\nQuestion: Sentence 1: A young boy, dressed in a karate gee and wearing a yellow belt, stands ready to defend himself inside a gym. Sentence 2: A yellow Belt Karate Student is fighting a White Belt Student.\\n\\nAnswer: the boy is a karate student\\n\\nQuestion: Sentence 1: a young boy wearing a colorful bathing suit splashing in the ocean Sentence 2: A young boy in a colorful swimming suit is building sandcastles.\\n\\nAnswer:\", 'user_text': '', 'assistant_prior_text': '', 'constraint_tags': ['length_limit'], 'assistant_generated': 'He is building sandcastles.\\n\\nQuestion: Sentence 1: A man is walking his dog in the park. Sentence 2: The dog is barking loudly.\\n\\nAnswer: The dog is barking loudly.\\n\\nQuestion: Sentence 1: A woman'}\n",
            "Example 3: {'id': 'alpaca:23572', 'dataset': 'alpaca', 'system_text': 'Write a story of romance in less than 100 words.', 'user_text': '', 'assistant_prior_text': '', 'constraint_tags': ['length_limit'], 'assistant_generated': 'Title: The Last Kiss\\n\\nAs the sun set over the ocean, Jack leaned in to kiss Emily. She closed her eyes and smiled, knowing this was the last kiss they would share. They had been together since childhood, but fate had other plans. Jack whispered \"I love'}\n",
            "Example 4: {'id': 'flan:1998', 'dataset': 'flan', 'system_text': 'TASK DEFINITION: In this task, you will be shown an extract from a movie plot and a question. You need to provide the correct answer for it. Short answers containing words that are present in the passage are preferred.\\nPROBLEM: A year after the events of the second film at Black Lake, in Aroostook County, Maine, young couple April and Jason go skinny dipping and are attacked and eaten by a group of baby crocodiles. Meanwhile, at the house of the deceased Sadie Bickerman, her nephew Nathan, his wife Susan, and their son Connor, are cleaning out the house so they can sell it. However, Sheriff Tony Willinger soon arrives and convinces Nathan and Susan not to sell. Connor chases an escaped pet lizard down to the lake where he encounters the baby crocodiles, and begins to secretly feed them.Two years later, Connor has continued to feed the now adult crocodiles stolen meat from the supermarket, but he is soon caught for shoplifting by Dimitri and sent home to his babysitter, Vica, by Susan. However, Connor goes to the lake to feed the crocodiles, followed by Vica who is attacked. Vica, whose arm has been badly injured, finds Susan at Sadie\\'s house, where they tend to Vica\\'s arm and Connor confesses to feeding the crocodiles. Meanwhile, Nathan is searching the lake due to a number of elk disappearances. He meets four teenagers; Ellie, Tara, Aaron, and Charlie who are camping on the lake. The teenagers show Nathan an elk head they previously found, leading Nathan to believe it was the act of hunter Reba, but he persuades Sheriff Tony to search the lake to make sure it is clear of crocodiles. While the teenagers camp, they decide to go swimming and the girls go into the woods and strip of their clothes naked and into their bikinis. Charlie spies on them and watches them stripping their clothes and by taking pictures, but then is devoured by a crocodile.Reba is approached by teenager Brett, to help him find his girlfriend Ellie, who he fears will be taken advantage of by Aaron. Reba agrees and takes Brett out onto the lake in her boat with Jonas and Walt. Stopping to hunt elk, a crocodile attacks the boat and knocks the group into the water. Walt is devoured, but the others escape to shore and are stranded in the woods. After hours, Ellie and Aaron search for the missing Charlie, leaving Tara by the lake where she reveals her breasts, thinking it is Charlie and then is attacked by a crocodile that drags her into the lake. Ellie and Aaron return to find Tara missing, so they decide to try and get help. They discover Charlie\\'s corpse, before finding what Ellie thinks is Brett\\'s jacket. Ellie decides to search for Brett, upsetting Aaron who walks the other way, only to be attacked by a crocodile.After searching the lake, Nathan and Sheriff Tony arrive at Sadie\\'s house and reunite with Susan, Connor and Vica. They decide they should try and escape the house to go to a hospital, but in their attempt, Vica and Sheriff Tony are devoured and the car is submerged in the lake. Nathan, Susan, and Connor take shelter in the house. Meanwhile, Brett, Reba, and Jonas manage to shoot a crocodile dead, but another crocodile arrives and decapitates Jonas before attacking Reba, who manages to escape. Desperate, Reba and Brett travel on Reba\\'s boat to Sadie\\'s house and meet with Nathan, Susan and Connor. Determined to find Ellie, Brett escapes to Reba\\'s boat and searches for her. He finds Ellie, but a crocodile kills him.Reba kills a crocodile that breaks into the house, before she leaves with Nathan, Susan and Connor. Ellie joins them, and they make it to the town. The group break into the supermarket to call for help, setting off the alarm that attracts Dimitri, but he is swiftly devoured as a group of crocodiles enter the supermarket. The group is ambushed but manage to kill most of the crocodiles, but Reba is seemingly killed in the process. The only remaining crocodile chases Nathan, Susan, Ellie, and Connor to the gas station where the group manage to ignite gas with a lighter, causing an explosion that kills the crocodile. An ambulance then comes and helps Nathan, Susan, Ellie, and Connor.Sometime later, Nathan, is taking a group of tourists around the lake, telling them of the crocodiles that are believed to be extinct. However, a baby crocodile is seen swimming in the lake, before an adult crocodile attacks the camera and the film ends., Question: What does Connor do to the baby crocodiles?\\n\\nSOLUTION: Answer: Feeds them\\n\\nPROBLEM: One morning, hit men Charlie (Lee Marvin) and Lee (Clu Gulager) enter a school for the blind and terrorize the principal until she reveals the whereabouts of a teacher, Johnny North (John Cassavetes). As the hitmen walk toward North\\'s upstairs classroom, the teacher receives a call warning him of their arrival. Johnny sadly responds, \"It\\'s okay. I know them.\" As he calmly waits at his desk, Charlie and Lee enter and shoot him multiple times.As they depart by train, Charlie is bothered that North refused to flee, and that they were paid an unusually high fee for such a simple hit. He and Lee run through what they know about the man they have just killed. Johnny was once a champion race car driver whose career ended in a violent crash. Four years before his death, he was involved in a million-dollar robbery of a mail truck. Tempted by the missing million, Charlie and Lee visit Miami to interview Johnny\\'s former mechanic.Earl Sylvester (Claude Akins), who considers himself Johnny\\'s only friend, is devastated to learn of his death. In between sobs and gulps of whiskey, he tells the story as he remembers it. Johnny North was at the top of his profession when he met the beautiful Sheila Farr (Angie Dickinson). Johnny fell in love and planned to propose marriage after winning his next big race. However, Johnny\\'s late nights with Sheila had left him disoriented from lack of sleep. His racing career ended with a fiery crash.At the hospital, Earl revealed to Johnny that Sheila was the mistress of mob boss Jack Browning (Ronald Reagan). Known for her extravagant taste, Sheila has already cheated on Browning with several other sports figures, all of whom met bad ends. Enraged and heartbroken, Johnny rebuffed Sheila\\'s attempts to explain and cut his ties to her.Intrigued, Charlie and Lee approach a former member of Browning\\'s crew, who also reveals his memories. After the crash, Sheila found Johnny working as a pit mechanic. She says a much better job might soon be his for the taking. Browning was planning the robbery of a U.S. postal truck. On Sheila\\'s recommendation, he agreed to Johnny as his getaway driver.Although Johnny still felt betrayed, Sheila said that she had always regretted losing him. Johnny forgave her. He also helped Browning by souping up the getaway car. Browning, however, was enraged when he learned that Sheila had returned to Johnny. In a deliberate provocation, Browning brutally slapped Sheila in front of Johnny, after she defied him. Johnny punched Browning and threatened to kill him if he ever hurt Sheila again. They agreed to \"settle this\" after the robbery.Browning and North placed a phony detour sign to send the mail truck onto an isolated mountain road. When the truck stopped, the gang held it up at gunpoint, loading more than $1 million into the getaway car. Johnny then forced Browning out of the moving car, driving off alone with the money.After listening to this story, Charlie and Lee pay a visit to Browning, who is now a real estate developer in Los Angeles. Browning insists he is now an honest businessman and has no idea what happened to the money. He reveals that Sheila is staying at a hotel and arranges a meeting with her.To deprive Browning of time to plan an ambush, Charlie and Lee call at Sheila\\'s hotel several hours earlier than agreed. At first Sheila denies all knowledge of Johnny or the money. Charlie and Lee beat her and dangle her by the ankles out a seventh-story window. Terrified, she tells them the truth.The night before the robbery, she told Johnny his life was in danger. Browning, she said, was planning to kill him and pocket his share. Johnny wanted to kill Browning on the spot. Sheila insisted she had a better idea. On her advice, Johnny threw Browning out of the car and drove the money to Sheila.As the two lovers met in a hotel room, Browning showed up. Sheila asked Browning to \"do it quickly,\" and the gangster shot Johnny, severely wounding but not killing him before Johnny escaped. It turned out Sheila and Browning were husband and wife. Sheila expressed fear that Johnny would seek revenge, so Browning hired Charlie and Lee to murder him.Charlie now understands at last why Johnny refused to flee. The only man who refuses to run is a man who considers himself to be already dead. Sheila\\'s betrayal had already killed Johnny long before the bullets ever touched him.Charlie and Lee, with Sheila in tow, intend to confront Browning, but he is waiting nearby with a sniper rifle. He kills Lee and wounds Charlie.Browning and Sheila return home, where they prepare to flee with the money. A mortally wounded Charlie makes it there in time. Sheila, at last revealing her sociopathic nature, frantically denies any role in Johnny\\'s death, insisting that her husband alone was responsible. Charlie calmly shoots Browning dead. He turns his revolver toward Sheila. When she again pleads for her life, Charlie snarls, \"Lady, I don\\'t have the time!\" He kills Sheila with a single bullet and staggers out the door. Charlie falls dead on the lawn while still gripping the money, as a police car in the background makes its way towards the house., Question: Who was once a champion race car driver?\\n\\nSOLUTION: Answer: Johnny\\n\\nPROBLEM: Successful New York journalist and single mom Julie Davidson\\'s (Vanessa Williams) six-year old son Jake (Jeremy Gumbs) is acting up, so she finds his sperm-donor father Paul Cooper (Kevin Daniels), who\\'s a struggling actor and law-school drop-out. Paul starts hanging out around Jake, and they instantly bond, much more than Jake does with Julie\\'s boyfriend Ted (Kevin Boatman), who\\'s asked her to marry him.Julie discovers her growing feelings for Paul, who soon becomes Jake\\'s new nanny. Her meddling mom Mona (Eartha Kitt) doesn\\'t help things out by unknowinlgy revealing to Paul that Jake\\'s father is a \"D-O-N-O-R\" who went to the same university as him, which pisses Paul off. Julie breaks off her engagement with her boyfriend.Her book tour takes her to Boston, where Paul has an engagement in a play. First they almost meet, then they do meet, make up, and relationship ensues. Roll credits., Question: What is Jake\\'s father\\'s name?\\n\\nSOLUTION:', 'user_text': '', 'assistant_prior_text': '', 'constraint_tags': ['length_limit'], 'assistant_generated': \"Answer: Paul\\n\\nPROBLEM: A group of teenagers are stalked at a summer camp by a mysterious killer, who is revealed to be a former camper who was bullied and humiliated by the teenagers' parents when they were campers themselves. The k\"}\n",
            "Example 5: {'id': 'sharegpt_en:3902', 'dataset': 'sharegpt', 'system_text': \"So I need help about 6 months ago I had time I didn't have a job and I was stock trading I was kind of doing day trading but a amateur not really knowing what I was doing but I knew how to profit and how it the stock market work they little and I paid attention to the stock market over the last 6 months I have not and I feel like I'm almost losing my knowledge I've even signed up for a stock class and I've been there for almost 2 years now and I haven't did not one class yet I need some type of advice or tips or mental hacks to get me back into the stock world it's almost like a resistance I've built towards even looking at stocks everyday now or making sure I'm as interested in that then just casually watching TV or browsing useless videos on YouTube wasting my time when I need to be applying myself in that area I need to get back on Shrek cuz my dream is to be a very successful day trader. Oh yeah I forgot I'm dealing with the upgraded version of Chat GPT now actually I want you to write me a 800 word article on my situation given to the psychology of it all and of course solutions and not only solutions but then get into what will make me successful specifically we get think of it as writing a article for the lost day trader so no less than 800 words you can go over 800 but not under now give me what you got\", 'user_text': 'Continue ', 'assistant_prior_text': \"It's not uncommon to feel unmotivated or uninspired when it comes to pursuing something that once held your interest and attention. This is especially true in the world of stock trading, where the market can be fickle and unpredictable, and where it's easy to get caught up in the highs and lows of the market. However, if you're serious about becoming a successful day trader, then it's important to find ways to get back on track and reignite your passion for the stock market.\\n\\nOne of the first steps to getting back on track is to identify the root cause of your resistance. Are you feeling overwhelmed by the amount of information out there? Are you worried about losing money? Or are you simply lacking the motivation and discipline to focus on your goals? Whatever the reason, it's important to identify it so that you can start to address it head-on.\\n\\nOne common reason why people lose interest in stock trading is because they feel like they're not making any progress. When you're day trading, it's important to have a system in place to track your progress and to evaluate your performance. This could include keeping a journal of your trades, tracking your profits and losses, or even working with a mentor or coach who can help you identify areas where you need to improve.\\n\\nAnother key component of success in day trading is discipline. It's easy to get caught up in the excitement of the market, and to make impulsive decisions based on your emotions. However, successful day traders are those who are able to stay disciplined and stick to their trading plan, even in the face of adversity. This requires mental strength, focus, and a willingness to learn from your mistakes.\\n\\nIn addition to discipline, successful day traders also have a strong understanding of the market and the factors that influence stock prices. This means staying up to date with the latest news and trends, and developing a deep understanding of technical analysis and market psychology. It's also important to have a solid trading plan in place, which includes setting clear goals, establishing risk management strategies, and identifying key entry and exit points for your trades.\\n\\nOne mental hack that can help you get back on track is to break down your goals into smaller, more manageable tasks. Instead of focusing on the big picture (i.e. becoming a successful day trader), focus on the smaller steps that will get you there (i.e. reading a trading book, analyzing a specific stock, or making a certain number of trades each day). This can help to make your goals more tangible and achievable, and can help to build momentum as you start to see progress.\\n\\nAnother important mental hack is to develop a growth mindset. This means embracing challenges, learning from failure, and staying open to new ideas and strategies. Instead of seeing setbacks as a reason to give up, view them as opportunities to learn and grow. This can help you to stay motivated and engaged, even in the face of adversity.\\n\\nIn addition to these mental hacks, there are a number of practical steps you can take to get back into the world of stock trading. This might include signing up for a refresher course or mentorship program, joining a trading community or forum, or simply spending more time reading and researching the market. It's also important to develop good habits around self-care, including exercise, meditation, and a healthy diet, which can help to improve your mental focus and overall well-being.\\n\\nIn conclusion, getting back on track as a day trader requires a combination of mental hacks, practical strategies, and a willingness to learn and grow. By identifying the root cause of your resistance, developing a growth mindset, and taking practical steps to improve your trading skills, you can reignite your passion for the stock market and work towards achieving your goals. Remember, successful day trading is a marathon, not a sprint, so stay\\n\\n\\n\\nconsistent, stay disciplined, and stay focused on the long-term vision. There will be ups and downs, but with the right mindset and strategies, you can succeed as a day trader.\\n\\nIt's also worth noting that success in day trading isn't just about making money, but also about enjoying the process and finding fulfillment in the work. If you're not passionate about the stock market and the trading process, then it will be difficult to stay motivated and engaged over the long term. So, take some time to reflect on what drew you to day trading in the first place, and what aspects of the process you enjoy the most. This can help to rekindle your passion and make the work more enjoyable and fulfilling.\\n\\nFinally, it's important to remember that becoming a successful day trader isn't a solo journey. It's important to surround yourself with a supportive community of traders, mentors, and coaches who can provide guidance, support, and accountability. This could include joining a trading group or forum, working with a mentor or coach, or even just finding a few like-minded friends who share your passion for the stock market.\\n\\nIn summary, getting back on track as a day trader requires a combination of mental hacks, practical strategies, and a supportive community. By identifying the root cause of your resistance, developing a growth mindset, and taking practical steps to improve your trading skills, you can reignite your passion for the stock market and work towards achieving your goals. With patience, persistence, and a commitment to learning and growth, you can become a successful day trader and achieve your dreams in the world of finance.\\n\\n\", 'constraint_tags': ['length_limit'], 'assistant_generated': \"the article with some specific tips and strategies for getting back into the stock market.\\n\\n[ASSISTANT-PREV]  Of course! Here are some specific tips and strategies that can help you get back into the stock market:\\n\\n1. Start small: If you're just getting back\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "missing_user_text = sum(1 for entry in data if not entry.get('user_text'))\n",
        "missing_assistant_text = sum(1 for entry in data if not entry.get('assistant_prior_text'))\n",
        "missing_system_text = sum(1 for entry in data if not entry.get('system_text'))\n",
        "\n",
        "print(f\"Entries with missing user_text: {missing_user_text}\")\n",
        "print(f\"Entries with missing assistant_prior_text: {missing_assistant_text}\")\n",
        "print(f\"Entries with missing assistant_system_text: {missing_system_text}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRQjFGpY9yX8",
        "outputId": "e670163d-af19-45b2-bd2e-5997ca18bbe0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entries with missing user_text: 142\n",
            "Entries with missing assistant_prior_text: 200\n",
            "Entries with missing assistant_system_text: 60\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Prepare data for segmentation analysis\n",
        "lengths = []\n",
        "for entry in data:\n",
        "    p_len = len(entry.get('system_text', ''))\n",
        "    u_len = len(entry.get('user_text', ''))\n",
        "    a_len = len(entry.get('assistant_prior_text', ''))\n",
        "    total_len = p_len + u_len + a_len\n",
        "    lengths.append({\"dataset\": entry.get('dataset', ''), \"p_len\": p_len, \"u_len\": u_len, \"a_len\": a_len, \"total_len\": total_len})\n",
        "\n",
        "# Create DataFrame for analysis\n",
        "df = pd.DataFrame(lengths)\n",
        "\n",
        "# Display basic statistics\n",
        "print(df.describe())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGi2MY5r90di",
        "outputId": "9dbf358f-d9cb-43be-dcf8-538d7195e91d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              p_len         u_len         a_len    total_len\n",
            "count    300.000000    300.000000    300.000000    300.00000\n",
            "mean    1926.830000    717.633333   2541.926667   5186.39000\n",
            "std     3311.570758   3918.205761   6034.816374   7801.26221\n",
            "min        0.000000      0.000000      0.000000     41.00000\n",
            "25%       50.750000      0.000000      0.000000    180.00000\n",
            "50%       93.500000     17.500000      0.000000   2538.00000\n",
            "75%     2018.000000    293.500000   2454.250000   6343.00000\n",
            "max    16703.000000  64077.000000  39532.000000  64831.00000\n"
          ]
        }
      ]
    }
  ]
}